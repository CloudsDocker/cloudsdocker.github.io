---
layout: posts
title: Java JIT compiler
tags:
- java
- JIT
---

# This is talking about Java JIT (Just-In-Time) compiler

- That trade-off is one reason that the compiler executes the interpreted code first—the compiler can figure out which methods are called frequently enough to warrant their compilation.
The second reason is one of optimization: the more times that the JVM executes a particular method or loop, the more information it has about that code. This allows the JVM to make a number of optimizations when it compiles the code.

- At some point in time, the suminstance variable must reside in main memory, but retrieving a value from main memory is an expensive operation that takes multiple cycles to complete. If the value of sumwere to be retrieved from (and stored back to) main memory on every iteration of this loop, performance would be dismal. Instead, the compiler will load a register with the initial value of sum, perform the loop using that value in the register, and then (at an indeterminate point in time) store the final result from the register back to main memory.
This kind of optimization is very effective, but it means that the semantics of thread synchronization (see Chapter 9) are crucial to the behavior of the application

- One thread cannot see the value of a variable stored in the register used by another thread; synchronization makes it possible to know exactly when the register is stored to main memory and available to other threads.
Register usage is a general optimization of the compiler, and when escape analysis is enabled (see the end of this chapter), register use is quite aggressive.


- If the size of your heap will be less than about 3 GB, the 32-bit version of Java will be faster and have a smaller footprint. This is because the memory references within the JVM will be only 32 bits, and manipulating those memory references is less expensive than manipulating 64-bit references (even if you have a 64-bit CPU). The 32-bit references also use less memory.

- JVM developers (and even some tools) often refer to the compilers by the names C1
(compiler 1, client compiler) and C2 (compiler 2, server compiler).

- The primary difference between the two compilers is their aggressiveness in compiling
code. The client compiler begins compiling sooner than the server compiler does. This
means that during the beginning of code execution, the client compiler will be faster,
because it will have compiled correspondingly more code than the server compiler.

- The engineering trade-off here is the knowledge the server compiler gains while it waits:
that knowledge allows the server compiler to make better optimizations in the compiled
code. Ultimately, code produced by the server compiler will be faster than that produced
by the client compiler. From a user’s perspective, the benefit to that trade-off is based
on how long the program will run, and how important the startup time of the program
is.

- The obvious question here is why there needs to be a choice at all: couldn’t the JVM
start with the client compiler, and then use the server compiler as code gets hotter? That
technique is known as tiered compilation. With tiered compilation, code is first compiled
by the client compiler; as it becomes hot, it is recompiled by the server compiler.

- To use tiered compilation, specify
the server compiler (either with -server or by ensuring it is the default for the particular
Java installation being used), and ensure that the Java command line includes the flag
-XX:+TieredCompilation (the default value of which is false). In Java 8, tiered compilation
is enabled by default.

- The client compiler is most often used when fast startup is the primary objective.

1. The client compiler is most useful when the startup of an application
is the overriding performance concern.
2. Tiered compilation can achieve startup times very close to those
obtained from the client compiler.

- It is also interesting that tiered compilation is always slightly better than the standard
server compiler. In theory, once the program has run enough to compile all the hot
spots, the server compiler might be expected to achieve the best (or at least equal) performance.
But in any application, there will almost always be some small section of code
that is infrequently executed. It is better to compile that code—even if the compilation
is not the best that might be achieved—than to execute that code in interpreted mode.

1. For jobs that run in a fixed amount of time, choose the compiler
based on which one is the fastest at executing the actual job.
1. Tiered compilation provides a reasonable default choice for batch
jobs.

- For long-running applications, always choose the server compiler, preferably in conjunction with tiered compilation.























